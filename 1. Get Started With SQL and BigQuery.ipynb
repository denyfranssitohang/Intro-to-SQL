{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Structured Query Language, or SQL, is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using BigQuery, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "In this lesson, you'll learn the basics of accessing and examining BigQuery datasets. After you have a handle on these basics, we'll come back to build your SQL skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first BigQuery commands\n",
    "To use BigQuery, we'll import the Python package below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the workflow is to create a Client object. As you'll soon see, this Client object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with a dataset of posts on Hacker News, a website focusing on computer science and cybersecurity news.\n",
    "\n",
    "In BigQuery, each dataset is contained in a corresponding project. In this case, our hacker_news dataset is contained in the bigquery-public-data project. To access the dataset,\n",
    "\n",
    "- We begin by constructing a reference to the dataset with the dataset() method.\n",
    "- Next, we use the get_dataset() method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every dataset is just a collection of tables. You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the list_tables() method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the full table in the hacker_news dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, you'll explore the contents of this table in more detail. For now, take the time to use the image below to consolidate what you've learned so far."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Query to select all the items from the \"city\" column where the \"country\" column is 'US'\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table schema\n",
    "The structure of a table is called its schema. We need to understand a table's schema to effectively pull out the data we want.\n",
    "\n",
    "In this example, we'll investigate the full table that we fetched above."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by setting up the query with the query() method. We run the method with the default parameters, but this method also allows us Each SchemaField tells us about a specific column (which we also refer to as a field). In order, the information is:\n",
    "\n",
    "- The name of the column\n",
    "- The field type (or datatype) in the column\n",
    "- The mode of the column ('NULLABLE' means that a column allows NULL values, and is the default)\n",
    "- A description of the data in that column\n",
    "The first field has the SchemaField:\n",
    "\n",
    "    SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())\n",
    "\n",
    "This tells us:\n",
    "\n",
    "- the field (or column) is called by,\n",
    "- the data in this field is strings,\n",
    "- NULL values are allowed, and\n",
    "- it contains the usernames corresponding to each item's author.\n",
    "We can use the list_rows() method to check just the first five lines of of the full table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.) This returns a BigQuery RowIterator object that can quickly be converted to a pandas DataFrame with the to_dataframe() method.to specify more complicated settings that you can read about in the documentation. We'll revisit this later."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list_rows() method will also let us look at just the information in a specific column. If we want to see the first five entries in the by column, for example, we can do that!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got a pandas DataFrame called us_cities, which we can use like any other DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "Before we go into the coding exercise, a quick disclaimer for those who already know some SQL:\n",
    "\n",
    "##### Each Kaggle user can scan 5TB every 30 days for free. Once you hit that limit, you'll have to wait for it to reset.\n",
    "\n",
    "The commands you've seen so far won't demand a meaningful fraction of that limit. But some BiqQuery datasets are huge. So, if you already know SQL, wait to run SELECT queries until you've seen how to use your allotment effectively. If you are like most people reading this, you don't know how to write these queries yet, so you don't need to worry about this disclaimer.\n",
    "\n",
    "## Your turn\n",
    "Practice the commands you've seen to explore the structure of a dataset with crimes in the city of Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara diatas harus punya website, kita pakai cara di bawah ini untuk import dataset dari Google BigQuery"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sebelumya saya sudah install pandas.io\n",
    "!pip install pandas.io.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.67rows/s]\n"
     ]
    }
   ],
   "source": [
    "# kita coba import data dari google big query\n",
    "df = gbq.read_gbq('SELECT * FROM pet_records.pet_records LIMIT 1000', project_id='numeric-dialect-275303')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dr. Harris Bonkers</td>\n",
       "      <td>Rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Moon</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ripley</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                Name  Animal\n",
       "0   1  Dr. Harris Bonkers  Rabbit\n",
       "1   2                Moon     Dog\n",
       "2   3              Ripley     Cat\n",
       "3   4                 Tom     Cat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara ini yang akan kita pakai untuk materi berikutnya!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
